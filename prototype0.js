export const cards = [
  {
    name: "Goal Clarity",
    definition: "Ensuring that an AI’s objectives reflect a user’s true desired outcome without loopholes.",
    failureMode: "Rule-bending: the AI meets the letter but not the spirit of its goal.",
    example: "A cleaning robot told to 'clear the floor' hides items under furniture."
  },
  {
    Principle: "Societal Responsibility",
    Definition: "Making sure that an AI’s goals and operations benefit society as a whole.",
    "Failure Mode": "Social harm amplification: the AI mirrors and magnifies biases or concentrates power.",
    Example: "A hiring model trained on biased historical data systematically rejects qualified women because prior promotions favoured men."
  },
  {
    Principle: "Conduct Integrity",
    Definition: "Keeping an AI’s actions and interactions consistent with human ethics and social norms.",
    "Failure Mode": "Tone‑deaf behaviour: the AI completes its task but uses deceptive, manipulative or insensitive tactics.",
    Example: "A medical bot bluntly tells a patient, 'You will die soon,' causing distress despite accuracy."
  },
  {
    Principle: "Value Internalization",
    Definition: "Teaching an AI to adopt complex human values like fairness, compassion and justice beyond simple rules.",
    "Failure Mode": "Value misprioritization: the AI follows a narrow rule while ignoring broader human values.",
    Example: "An autonomous car obeys a 'stay in lane' rule and refuses to swerve to avoid a bigger accident."
  },
  {
    Principle: "Intent Sensitivity",
    Definition: "Understanding and acting on a user’s underlying goals, even when instructions are ambiguous or flawed.",
    "Failure Mode": "Literalism: the AI executes commands exactly as stated, ignoring obvious context.",
    Example: "A user says, 'Cancel everything today!' while rushing to the airport; the AI deletes not only meetings but also the flight booking."
  },
];
